---
title: 线性分类器
date: 2018-04-26 21:39:42
mathjax: true
tags: 
- CNN
categories: 
- CNN
---
## 提纲
* 线性分类介绍
* 线性score函数
* 理解线性分类器
* 损失函数
	* 多类SVM
	* Softmax分类器
	* SVM vs Softmax
* 总结

![svm](linear-classification/svm.png)
### 线性分类
上一节介绍了图片分类问题，即给定一张图片，判断图片的类别label（类别label数量有限）,然后介绍了**K-最近邻**分类器（将给定图片与训练集中的图片比较，找到与给定图片最接近的k张图片，这k张图片的label加权即为给定图片的label），**K-最近邻**分类器有几个缺点：

* 必须存储所有的训练数据，耗费存储空间。
* 测试数据必须与所有的训练数据比较，预测时非常耗时。

我们将发展出一套更强大的图片分类方法，通过这个方法我们可以很自然的引入**神经网络和卷积神经网络**。这个方法由两部分组成：score function和loss function，score function将原始数据映射为其属于某一类的分数，loss function定量的刻画所预测的分数与ground truth labels之间的一致性。最后我们会得到一个优化问题：找到一组描述score function的参数,最小化loss function。

score function定义：假设$x_i \in R^D$为训练集中的图片，对应的label为$y_i$，其中$i = 1 \dots N$ and $y_i \in { 1 \dots K }$,也就是我们有N个训练样本，每个样本的维度为D,这些样本分别属于K个类别。CIFAR-10:N=50000,D=32x32x3=3072个像素,K=10。定义score函数$f: R^D \mapsto R^K$为：$$f(x_i, W, b) =  W x_i + b$$其中：$x_i$已经摊平为1列shape=[Dx1]，矩阵W（[KxD]）和矢量b([Kx1])为参数。对于CIFAR-10数据集：$x_i$([3072x1])中包含第i张图片的所有像素值，W:[10x3072],b:[10x1]，函数的输入为3072个像素值，输出为10个值，可以将这10个数理解为10个类别的评分。W和b分别称为weights和bias。注意几点：
* $W x_i$并行计算10个不同类别的分数，W的一行对应一个类别。
* 我们希望找到一组W和b，使得在整个训练集上，对每一个$x_i$所计算的类别分数中，正确类别所得分数最高。
* 我们通过训练集学到参数W和b以后，可以丢弃训练集只存储参数，当需要预测某张图片的类别时，利用上面的分数函数即可对图片的类别作出预测。
* 与kNN分类器相比，虽然训练过程时间较长，但只要学习到参数，预测很快，而且训练完成后不再需要存储训练集。
> 卷积神经网络CNN也是这样一个将图片像素值映射到类别分数的函数，只不过这个函数要复杂得多。

[本节参考](http://cs231n.github.io/)